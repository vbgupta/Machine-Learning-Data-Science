{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python385jvsc74a57bd0ce522b9940690b3589ab5dd88989ddc76f7f45ba7af808aff168205ed6895099",
      "display_name": "Python 3.8.5 64-bit ('school_env': venv)",
      "language": "python"
    },
    "colab": {
      "name": "SUBMISSION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-IFaT3I18Kb"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnBaBK8l18Ki"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import ast\n",
        "import json\n",
        "from numpy import nan\n",
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP5q-WcK18Kk"
      },
      "source": [
        "## Pathing to Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "ZElYY8LY18Kk",
        "outputId": "576f44d7-ba63-4404-f7c1-def2149d76b2"
      },
      "source": [
        "data_train = 'train.csv'\n",
        "train = pd.read_csv(data_train)\n",
        "print(len(train))\n",
        "data_test = 'test.csv'\n",
        "test = pd.read_csv(data_test)\n",
        "\n",
        "train.tail(3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id belongs_to_collection    budget  \\\n",
              "2997  2998                   NaN  65000000   \n",
              "2998  2999                   NaN  42000000   \n",
              "2999  3000                   NaN  35000000   \n",
              "\n",
              "                                                 genres  \\\n",
              "2997  [{'id': 80, 'name': 'Crime'}, {'id': 28, 'name...   \n",
              "2998  [{'id': 35, 'name': 'Comedy'}, {'id': 10749, '...   \n",
              "2999  [{'id': 53, 'name': 'Thriller'}, {'id': 28, 'n...   \n",
              "\n",
              "                              homepage    imdb_id original_language  \\\n",
              "2997                               NaN  tt0116908                en   \n",
              "2998    http://www.alongcamepolly.com/  tt0343135                en   \n",
              "2999  http://www.abductionthefilm.com/  tt1600195                en   \n",
              "\n",
              "               original_title  \\\n",
              "2997  The Long Kiss Goodnight   \n",
              "2998         Along Came Polly   \n",
              "2999                Abduction   \n",
              "\n",
              "                                               overview  popularity  ...  \\\n",
              "2997  Samantha Caine, suburban homemaker, is the ide...   14.482345  ...   \n",
              "2998  Reuben Feffer is a guy who's spent his entire ...   15.725542  ...   \n",
              "2999  A young man sets out to uncover the truth abou...   10.512109  ...   \n",
              "\n",
              "     release_date runtime                          spoken_languages    status  \\\n",
              "2997     10/11/96   120.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
              "2998      1/16/04    90.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
              "2999      9/22/11   106.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
              "\n",
              "                                                tagline  \\\n",
              "2997               What's forgotten is not always gone.   \n",
              "2998  For the most cautious man on Earth, life is ab...   \n",
              "2999          They stole his life. He's taking it back.   \n",
              "\n",
              "                        title  \\\n",
              "2997  The Long Kiss Goodnight   \n",
              "2998         Along Came Polly   \n",
              "2999                Abduction   \n",
              "\n",
              "                                               Keywords  \\\n",
              "2997  [{'id': 441, 'name': 'assassination'}, {'id': ...   \n",
              "2998  [{'id': 966, 'name': 'beach'}, {'id': 2676, 'n...   \n",
              "2999  [{'id': 591, 'name': 'cia'}, {'id': 822, 'name...   \n",
              "\n",
              "                                                   cast  \\\n",
              "2997  [{'cast_id': 10, 'character': 'Samantha Caine ...   \n",
              "2998  [{'cast_id': 8, 'character': 'Reuben Feffer', ...   \n",
              "2999  [{'cast_id': 2, 'character': 'Nathan Harper', ...   \n",
              "\n",
              "                                                   crew    revenue  \n",
              "2997  [{'credit_id': '52fe443a9251416c7502d579', 'de...   89456761  \n",
              "2998  [{'credit_id': '556f817b9251410866000a63', 'de...  171963386  \n",
              "2999  [{'credit_id': '5391990d0e0a260fb5001629', 'de...   82087155  \n",
              "\n",
              "[3 rows x 23 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>belongs_to_collection</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>homepage</th>\n      <th>imdb_id</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>popularity</th>\n      <th>...</th>\n      <th>release_date</th>\n      <th>runtime</th>\n      <th>spoken_languages</th>\n      <th>status</th>\n      <th>tagline</th>\n      <th>title</th>\n      <th>Keywords</th>\n      <th>cast</th>\n      <th>crew</th>\n      <th>revenue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2997</th>\n      <td>2998</td>\n      <td>NaN</td>\n      <td>65000000</td>\n      <td>[{'id': 80, 'name': 'Crime'}, {'id': 28, 'name...</td>\n      <td>NaN</td>\n      <td>tt0116908</td>\n      <td>en</td>\n      <td>The Long Kiss Goodnight</td>\n      <td>Samantha Caine, suburban homemaker, is the ide...</td>\n      <td>14.482345</td>\n      <td>...</td>\n      <td>10/11/96</td>\n      <td>120.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>What's forgotten is not always gone.</td>\n      <td>The Long Kiss Goodnight</td>\n      <td>[{'id': 441, 'name': 'assassination'}, {'id': ...</td>\n      <td>[{'cast_id': 10, 'character': 'Samantha Caine ...</td>\n      <td>[{'credit_id': '52fe443a9251416c7502d579', 'de...</td>\n      <td>89456761</td>\n    </tr>\n    <tr>\n      <th>2998</th>\n      <td>2999</td>\n      <td>NaN</td>\n      <td>42000000</td>\n      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 10749, '...</td>\n      <td>http://www.alongcamepolly.com/</td>\n      <td>tt0343135</td>\n      <td>en</td>\n      <td>Along Came Polly</td>\n      <td>Reuben Feffer is a guy who's spent his entire ...</td>\n      <td>15.725542</td>\n      <td>...</td>\n      <td>1/16/04</td>\n      <td>90.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>For the most cautious man on Earth, life is ab...</td>\n      <td>Along Came Polly</td>\n      <td>[{'id': 966, 'name': 'beach'}, {'id': 2676, 'n...</td>\n      <td>[{'cast_id': 8, 'character': 'Reuben Feffer', ...</td>\n      <td>[{'credit_id': '556f817b9251410866000a63', 'de...</td>\n      <td>171963386</td>\n    </tr>\n    <tr>\n      <th>2999</th>\n      <td>3000</td>\n      <td>NaN</td>\n      <td>35000000</td>\n      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 28, 'n...</td>\n      <td>http://www.abductionthefilm.com/</td>\n      <td>tt1600195</td>\n      <td>en</td>\n      <td>Abduction</td>\n      <td>A young man sets out to uncover the truth abou...</td>\n      <td>10.512109</td>\n      <td>...</td>\n      <td>9/22/11</td>\n      <td>106.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>They stole his life. He's taking it back.</td>\n      <td>Abduction</td>\n      <td>[{'id': 591, 'name': 'cia'}, {'id': 822, 'name...</td>\n      <td>[{'cast_id': 2, 'character': 'Nathan Harper', ...</td>\n      <td>[{'credit_id': '5391990d0e0a260fb5001629', 'de...</td>\n      <td>82087155</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 23 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "m1rMl7wV18Km",
        "outputId": "de40152a-edb1-4b64-d3eb-71726f2d697e"
      },
      "source": [
        "test.head(3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                              belongs_to_collection  budget  \\\n",
              "0  3001  [{'id': 34055, 'name': 'PokÃ©mon Collection', '...       0   \n",
              "1  3002                                                NaN   88000   \n",
              "2  3003                                                NaN       0   \n",
              "\n",
              "                                              genres  \\\n",
              "0  [{'id': 12, 'name': 'Adventure'}, {'id': 16, '...   \n",
              "1  [{'id': 27, 'name': 'Horror'}, {'id': 878, 'na...   \n",
              "2  [{'id': 35, 'name': 'Comedy'}, {'id': 10749, '...   \n",
              "\n",
              "                                            homepage    imdb_id  \\\n",
              "0  http://www.pokemon.com/us/movies/movie-pokemon...  tt1226251   \n",
              "1                                                NaN  tt0051380   \n",
              "2                                                NaN  tt0118556   \n",
              "\n",
              "  original_language               original_title  \\\n",
              "0                ja           ãƒ‡ã‚£ã‚¢ãƒ«ã‚¬VSãƒ‘ãƒ«ã‚­ã‚¢VSãƒ€ãƒ¼ã‚¯ãƒ©ã‚¤   \n",
              "1                en  Attack of the 50 Foot Woman   \n",
              "2                en             Addicted to Love   \n",
              "\n",
              "                                            overview  popularity  ...  \\\n",
              "0  Ash and friends (this time accompanied by newc...    3.851534  ...   \n",
              "1  When an abused wife grows to giant size becaus...    3.559789  ...   \n",
              "2  Good-natured astronomer Sam is devastated when...    8.085194  ...   \n",
              "\n",
              "                                production_countries release_date runtime  \\\n",
              "0  [{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_...      7/14/07    90.0   \n",
              "1  [{'iso_3166_1': 'US', 'name': 'United States o...      5/19/58    65.0   \n",
              "2  [{'iso_3166_1': 'US', 'name': 'United States o...      5/23/97   100.0   \n",
              "\n",
              "                                    spoken_languages    status  \\\n",
              "0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
              "1           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
              "2           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
              "\n",
              "                                             tagline  \\\n",
              "0  Somewhere Between Time & Space... A Legend Is ...   \n",
              "1  A titanic beauty spreads a macabre wave of hor...   \n",
              "2          A Comedy About Lost Loves And Last Laughs   \n",
              "\n",
              "                          title  \\\n",
              "0  PokÃ©mon: The Rise of Darkrai   \n",
              "1   Attack of the 50 Foot Woman   \n",
              "2              Addicted to Love   \n",
              "\n",
              "                                            Keywords  \\\n",
              "0  [{'id': 11451, 'name': 'pokâˆšÂ©mon'}, {'id': 115...   \n",
              "1  [{'id': 9748, 'name': 'revenge'}, {'id': 9951,...   \n",
              "2  [{'id': 931, 'name': 'jealousy'}, {'id': 9673,...   \n",
              "\n",
              "                                                cast  \\\n",
              "0  [{'cast_id': 3, 'character': 'Tonio', 'credit_...   \n",
              "1  [{'cast_id': 2, 'character': 'Nancy Fowler Arc...   \n",
              "2  [{'cast_id': 11, 'character': 'Maggie', 'credi...   \n",
              "\n",
              "                                                crew  \n",
              "0  [{'credit_id': '52fe44e7c3a368484e03d683', 'de...  \n",
              "1  [{'credit_id': '55807805c3a3685b1300060b', 'de...  \n",
              "2  [{'credit_id': '52fe4330c3a36847f8041367', 'de...  \n",
              "\n",
              "[3 rows x 22 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>belongs_to_collection</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>homepage</th>\n      <th>imdb_id</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>popularity</th>\n      <th>...</th>\n      <th>production_countries</th>\n      <th>release_date</th>\n      <th>runtime</th>\n      <th>spoken_languages</th>\n      <th>status</th>\n      <th>tagline</th>\n      <th>title</th>\n      <th>Keywords</th>\n      <th>cast</th>\n      <th>crew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3001</td>\n      <td>[{'id': 34055, 'name': 'PokÃ©mon Collection', '...</td>\n      <td>0</td>\n      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 16, '...</td>\n      <td>http://www.pokemon.com/us/movies/movie-pokemon...</td>\n      <td>tt1226251</td>\n      <td>ja</td>\n      <td>ãƒ‡ã‚£ã‚¢ãƒ«ã‚¬VSãƒ‘ãƒ«ã‚­ã‚¢VSãƒ€ãƒ¼ã‚¯ãƒ©ã‚¤</td>\n      <td>Ash and friends (this time accompanied by newc...</td>\n      <td>3.851534</td>\n      <td>...</td>\n      <td>[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_...</td>\n      <td>7/14/07</td>\n      <td>90.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n      <td>Released</td>\n      <td>Somewhere Between Time &amp; Space... A Legend Is ...</td>\n      <td>PokÃ©mon: The Rise of Darkrai</td>\n      <td>[{'id': 11451, 'name': 'pokâˆšÂ©mon'}, {'id': 115...</td>\n      <td>[{'cast_id': 3, 'character': 'Tonio', 'credit_...</td>\n      <td>[{'credit_id': '52fe44e7c3a368484e03d683', 'de...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3002</td>\n      <td>NaN</td>\n      <td>88000</td>\n      <td>[{'id': 27, 'name': 'Horror'}, {'id': 878, 'na...</td>\n      <td>NaN</td>\n      <td>tt0051380</td>\n      <td>en</td>\n      <td>Attack of the 50 Foot Woman</td>\n      <td>When an abused wife grows to giant size becaus...</td>\n      <td>3.559789</td>\n      <td>...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>5/19/58</td>\n      <td>65.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>A titanic beauty spreads a macabre wave of hor...</td>\n      <td>Attack of the 50 Foot Woman</td>\n      <td>[{'id': 9748, 'name': 'revenge'}, {'id': 9951,...</td>\n      <td>[{'cast_id': 2, 'character': 'Nancy Fowler Arc...</td>\n      <td>[{'credit_id': '55807805c3a3685b1300060b', 'de...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3003</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 10749, '...</td>\n      <td>NaN</td>\n      <td>tt0118556</td>\n      <td>en</td>\n      <td>Addicted to Love</td>\n      <td>Good-natured astronomer Sam is devastated when...</td>\n      <td>8.085194</td>\n      <td>...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>5/23/97</td>\n      <td>100.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>A Comedy About Lost Loves And Last Laughs</td>\n      <td>Addicted to Love</td>\n      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 9673,...</td>\n      <td>[{'cast_id': 11, 'character': 'Maggie', 'credi...</td>\n      <td>[{'credit_id': '52fe4330c3a36847f8041367', 'de...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 22 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wQJ4pd518Kn"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "1. Combine the training and test sets for easier and better Preprocessing.\n",
        "2. Figure out what the columns that can impact the revenue a movie makes\n",
        "3. Look at the column typ and makes necessary changes to it.\n",
        "\n",
        "### Training Set and Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "DupMjG9118Ko",
        "outputId": "d28f8573-7fe9-4200-95ec-e1065d689ceb"
      },
      "source": [
        "full_data = pd.concat([train, test], axis = 0)\n",
        "print(full_data.shape )\n",
        "full_data.head(3)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7398, 23)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                              belongs_to_collection    budget  \\\n",
              "0   1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
              "1   2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
              "2   3                                                NaN   3300000   \n",
              "\n",
              "                                              genres  \\\n",
              "0                     [{'id': 35, 'name': 'Comedy'}]   \n",
              "1  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
              "2                      [{'id': 18, 'name': 'Drama'}]   \n",
              "\n",
              "                            homepage    imdb_id original_language  \\\n",
              "0                                NaN  tt2637294                en   \n",
              "1                                NaN  tt0368933                en   \n",
              "2  http://sonyclassics.com/whiplash/  tt2582802                en   \n",
              "\n",
              "                             original_title  \\\n",
              "0                    Hot Tub Time Machine 2   \n",
              "1  The Princess Diaries 2: Royal Engagement   \n",
              "2                                  Whiplash   \n",
              "\n",
              "                                            overview  popularity  ...  \\\n",
              "0  When Lou, who has become the \"father of the In...    6.575393  ...   \n",
              "1  Mia Thermopolis is now a college graduate and ...    8.248895  ...   \n",
              "2  Under the direction of a ruthless instructor, ...   64.299990  ...   \n",
              "\n",
              "  release_date runtime                          spoken_languages    status  \\\n",
              "0      2/20/15    93.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
              "1       8/6/04   113.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
              "2     10/10/14   105.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
              "\n",
              "                                             tagline  \\\n",
              "0  The Laws of Space and Time are About to be Vio...   \n",
              "1  It can take a lifetime to find true love; she'...   \n",
              "2    The road to greatness can take you to the edge.   \n",
              "\n",
              "                                      title  \\\n",
              "0                    Hot Tub Time Machine 2   \n",
              "1  The Princess Diaries 2: Royal Engagement   \n",
              "2                                  Whiplash   \n",
              "\n",
              "                                            Keywords  \\\n",
              "0  [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
              "1  [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
              "2  [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...   \n",
              "\n",
              "                                                cast  \\\n",
              "0  [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
              "1  [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
              "2  [{'cast_id': 5, 'character': 'Andrew Neimann',...   \n",
              "\n",
              "                                                crew     revenue  \n",
              "0  [{'credit_id': '59ac067c92514107af02c8c8', 'de...  12314651.0  \n",
              "1  [{'credit_id': '52fe43fe9251416c7502563d', 'de...  95149435.0  \n",
              "2  [{'credit_id': '54d5356ec3a3683ba0000039', 'de...  13092000.0  \n",
              "\n",
              "[3 rows x 23 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>belongs_to_collection</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>homepage</th>\n      <th>imdb_id</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>popularity</th>\n      <th>...</th>\n      <th>release_date</th>\n      <th>runtime</th>\n      <th>spoken_languages</th>\n      <th>status</th>\n      <th>tagline</th>\n      <th>title</th>\n      <th>Keywords</th>\n      <th>cast</th>\n      <th>crew</th>\n      <th>revenue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n      <td>14000000</td>\n      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n      <td>NaN</td>\n      <td>tt2637294</td>\n      <td>en</td>\n      <td>Hot Tub Time Machine 2</td>\n      <td>When Lou, who has become the \"father of the In...</td>\n      <td>6.575393</td>\n      <td>...</td>\n      <td>2/20/15</td>\n      <td>93.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>The Laws of Space and Time are About to be Vio...</td>\n      <td>Hot Tub Time Machine 2</td>\n      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n      <td>12314651.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n      <td>40000000</td>\n      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n      <td>NaN</td>\n      <td>tt0368933</td>\n      <td>en</td>\n      <td>The Princess Diaries 2: Royal Engagement</td>\n      <td>Mia Thermopolis is now a college graduate and ...</td>\n      <td>8.248895</td>\n      <td>...</td>\n      <td>8/6/04</td>\n      <td>113.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>It can take a lifetime to find true love; she'...</td>\n      <td>The Princess Diaries 2: Royal Engagement</td>\n      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n      <td>95149435.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>3300000</td>\n      <td>[{'id': 18, 'name': 'Drama'}]</td>\n      <td>http://sonyclassics.com/whiplash/</td>\n      <td>tt2582802</td>\n      <td>en</td>\n      <td>Whiplash</td>\n      <td>Under the direction of a ruthless instructor, ...</td>\n      <td>64.299990</td>\n      <td>...</td>\n      <td>10/10/14</td>\n      <td>105.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>The road to greatness can take you to the edge.</td>\n      <td>Whiplash</td>\n      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n      <td>13092000.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 23 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "uDj8eH7c18Ko",
        "outputId": "de93cc97-d9ee-40a9-a858-c13de429c304"
      },
      "source": [
        "dataframe = full_data.loc[:,['budget', 'original_language', 'popularity', 'runtime', 'release_date']]\n",
        "dataframe = dataframe.fillna(0)\n",
        "dataframe['original_language'] = dataframe['original_language'].astype('category')\n",
        "dataframe['original_language'] = dataframe['original_language'].cat.codes\n",
        "\n",
        "# Using the main dataframe `full_data` for this column\n",
        "full_data['genres'] = full_data['genres'].astype('str')\n",
        "dataframe['release_date'] = pd.to_datetime(dataframe['release_date'])\n",
        "dataframe['release_date'] = dataframe['release_date'].dt.year\n",
        "dataframe.head(3)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     budget  original_language  popularity  runtime  release_date\n",
              "0  14000000                 10    6.575393     93.0          2015\n",
              "1  40000000                 10    8.248895    113.0          2004\n",
              "2   3300000                 10   64.299990    105.0          2014"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>budget</th>\n      <th>original_language</th>\n      <th>popularity</th>\n      <th>runtime</th>\n      <th>release_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14000000</td>\n      <td>10</td>\n      <td>6.575393</td>\n      <td>93.0</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>40000000</td>\n      <td>10</td>\n      <td>8.248895</td>\n      <td>113.0</td>\n      <td>2004</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3300000</td>\n      <td>10</td>\n      <td>64.299990</td>\n      <td>105.0</td>\n      <td>2014</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylQ27AWM18Kp"
      },
      "source": [
        "for i in range(len(full_data.genres)):\n",
        "\n",
        "  try:\n",
        "    x = eval(full_data.genres[i])\n",
        "    genres = [sub['name'] for sub in x]\n",
        "    full_data.genres[i] = genres\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "K8wTIL-n18Kq",
        "outputId": "06ff9531-0868-4fbd-d22f-d0c664ea895a"
      },
      "source": [
        "genr = full_data['genres'].copy()\n",
        "dataframe = pd.concat([dataframe, genr], axis = 1)\n",
        "dataframe.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     budget  original_language  popularity  runtime  release_date  \\\n",
              "0  14000000                 10    6.575393     93.0          2015   \n",
              "1  40000000                 10    8.248895    113.0          2004   \n",
              "2   3300000                 10   64.299990    105.0          2014   \n",
              "3   1200000                 16    3.174936    122.0          2012   \n",
              "4         0                 24    1.148070    118.0          2009   \n",
              "\n",
              "                                              genres  \n",
              "0                     [{'id': 35, 'name': 'Comedy'}]  \n",
              "1  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...  \n",
              "2                      [{'id': 18, 'name': 'Drama'}]  \n",
              "3  [{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...  \n",
              "4  [{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>budget</th>\n      <th>original_language</th>\n      <th>popularity</th>\n      <th>runtime</th>\n      <th>release_date</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14000000</td>\n      <td>10</td>\n      <td>6.575393</td>\n      <td>93.0</td>\n      <td>2015</td>\n      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>40000000</td>\n      <td>10</td>\n      <td>8.248895</td>\n      <td>113.0</td>\n      <td>2004</td>\n      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3300000</td>\n      <td>10</td>\n      <td>64.299990</td>\n      <td>105.0</td>\n      <td>2014</td>\n      <td>[{'id': 18, 'name': 'Drama'}]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1200000</td>\n      <td>16</td>\n      <td>3.174936</td>\n      <td>122.0</td>\n      <td>2012</td>\n      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>24</td>\n      <td>1.148070</td>\n      <td>118.0</td>\n      <td>2009</td>\n      <td>[{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hDmMmllG18Kr",
        "outputId": "d5617df4-b31c-4ee0-e413-a507ea0c0eeb"
      },
      "source": [
        "dataframe['genres'] = dataframe['genres'].astype(str)\n",
        "dataframe['genres'] = dataframe['genres'].str.split(\",\",n = 3, expand = True)\n",
        "dataframe['genres'] = dataframe['genres'].replace('\"[', '').replace(']\"', '').replace(\"'\", '')\n",
        "dataframe['genres'] = dataframe['genres'].str.strip('[]').astype('category')\n",
        "dataframe['genres'] = dataframe['genres'].cat.codes\n",
        "dataframe.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     budget  original_language  popularity  runtime  release_date  genres\n",
              "0  14000000                 10    6.575393     93.0          2015      32\n",
              "1  40000000                 10    8.248895    113.0          2004      32\n",
              "2   3300000                 10   64.299990    105.0          2014      29\n",
              "3   1200000                 16    3.174936    122.0          2012      35\n",
              "4         0                 24    1.148070    118.0          2009      31"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>budget</th>\n      <th>original_language</th>\n      <th>popularity</th>\n      <th>runtime</th>\n      <th>release_date</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14000000</td>\n      <td>10</td>\n      <td>6.575393</td>\n      <td>93.0</td>\n      <td>2015</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>40000000</td>\n      <td>10</td>\n      <td>8.248895</td>\n      <td>113.0</td>\n      <td>2004</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3300000</td>\n      <td>10</td>\n      <td>64.299990</td>\n      <td>105.0</td>\n      <td>2014</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1200000</td>\n      <td>16</td>\n      <td>3.174936</td>\n      <td>122.0</td>\n      <td>2012</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>24</td>\n      <td>1.148070</td>\n      <td>118.0</td>\n      <td>2009</td>\n      <td>31</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLdGAjAs18Ks"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VeD_IlI18Ks",
        "outputId": "7ce3f34e-c172-4553-d7be-c8773e4e0dc2"
      },
      "source": [
        "y = train['revenue']\n",
        "print(len(y))\n",
        "y.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    12314651\n",
              "1    95149435\n",
              "2    13092000\n",
              "3    16000000\n",
              "4     3923970\n",
              "Name: revenue, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9hZUSAt18Ku"
      },
      "source": [
        "### Lets now separate the dataframe in X_train and X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6tZ6ege18Ku"
      },
      "source": [
        "X_train = dataframe.iloc[:3000, :]\n",
        "X_test = dataframe.iloc[3000:, :]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3r71W9U18Ku"
      },
      "source": [
        "# Filling in the missing values in `runtime` column\n",
        "\n",
        "X_train['runtime'].fillna(X_train['runtime'].median(), inplace = True)\n",
        "X_test['runtime'].fillna(X_test['runtime'].median(), inplace = True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmFmVJGa18Ku"
      },
      "source": [
        "### Implimenting MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5QnVqSU618Ku",
        "outputId": "5803a06f-29b8-48a1-c2bc-c3ef4c980ed3"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_train = pd.DataFrame(X_train, columns= dataframe.columns)\n",
        "X_train.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     budget  original_language  popularity   runtime  release_date  genres\n",
              "0  0.036842           0.214286    0.022340  0.275148      0.444444    0.65\n",
              "1  0.105263           0.214286    0.028025  0.334320      0.333333    0.65\n",
              "2  0.008684           0.214286    0.218457  0.310651      0.434343    0.50\n",
              "3  0.003158           0.357143    0.010787  0.360947      0.414141    0.80\n",
              "4  0.000000           0.547619    0.003901  0.349112      0.383838    0.60"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>budget</th>\n      <th>original_language</th>\n      <th>popularity</th>\n      <th>runtime</th>\n      <th>release_date</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.036842</td>\n      <td>0.214286</td>\n      <td>0.022340</td>\n      <td>0.275148</td>\n      <td>0.444444</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.105263</td>\n      <td>0.214286</td>\n      <td>0.028025</td>\n      <td>0.334320</td>\n      <td>0.333333</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.008684</td>\n      <td>0.214286</td>\n      <td>0.218457</td>\n      <td>0.310651</td>\n      <td>0.434343</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.003158</td>\n      <td>0.357143</td>\n      <td>0.010787</td>\n      <td>0.360947</td>\n      <td>0.414141</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.547619</td>\n      <td>0.003901</td>\n      <td>0.349112</td>\n      <td>0.383838</td>\n      <td>0.60</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-4DRXwxO18Kv",
        "outputId": "51a03752-95e8-4def-df52-600f62b3980c"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "X_test = pd.DataFrame(X_test, columns= dataframe.columns)\n",
        "X_test.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     budget  original_language  popularity   runtime  release_date    genres\n",
              "0  0.000000           0.488372    0.007035  0.281250          0.37  0.666667\n",
              "1  0.000338           0.232558    0.006502  0.203125          0.88  0.769231\n",
              "2  0.000000           0.232558    0.014768  0.312500          0.27  0.820513\n",
              "3  0.026154           0.325581    0.015701  0.406250          0.40  0.743590\n",
              "4  0.007692           0.232558    0.005877  0.287500          0.35  0.846154"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>budget</th>\n      <th>original_language</th>\n      <th>popularity</th>\n      <th>runtime</th>\n      <th>release_date</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.488372</td>\n      <td>0.007035</td>\n      <td>0.281250</td>\n      <td>0.37</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000338</td>\n      <td>0.232558</td>\n      <td>0.006502</td>\n      <td>0.203125</td>\n      <td>0.88</td>\n      <td>0.769231</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.232558</td>\n      <td>0.014768</td>\n      <td>0.312500</td>\n      <td>0.27</td>\n      <td>0.820513</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.026154</td>\n      <td>0.325581</td>\n      <td>0.015701</td>\n      <td>0.406250</td>\n      <td>0.40</td>\n      <td>0.743590</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.007692</td>\n      <td>0.232558</td>\n      <td>0.005877</td>\n      <td>0.287500</td>\n      <td>0.35</td>\n      <td>0.846154</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrkF4vGj18Kv",
        "outputId": "d051cedf-8e3c-413b-dad3-5c31ce506081"
      },
      "source": [
        "print(\"Training Set Length is:\", len(X_train))\n",
        "print(\"Testing Set Length is:\", len(X_test))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Length is: 3000\nTesting Set Length is: 4398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-piu7dS18Kw"
      },
      "source": [
        "## ML Models to Predict `revenue`\n",
        "\n",
        "1. RandomForestRegressor\n",
        "2. XGBRegressor\n",
        "3. ANN Model Deep Learning\n",
        "3. LGBMRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ3DEvVmVoxK"
      },
      "source": [
        "### RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWtOG67Y18Kw"
      },
      "source": [
        "# RandomForestRegressor\n",
        "rf = RandomForestRegressor(random_state=44)\n",
        "rf.fit(X_train, y)\n",
        "y_preds_rf = rf.predict(X_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB1K5c6p18Kw",
        "outputId": "3e5bb3bc-e90c-4b5b-fe53-215bad0d4923"
      },
      "source": [
        "y_preds_rf # RSMLE = 2.55753"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8490865.42,  9894133.31,  7857207.55, ..., 46395423.7 ,\n",
              "       20997351.04, 17018240.99])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_8FEOEe18Kw"
      },
      "source": [
        "### Hyperparameter Tuning `RandomForest`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy7ipJTI18Kw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b9ff03-fdc7-4f30-9739-213234058f36"
      },
      "source": [
        "param_grid = [\n",
        "{'n_estimators': [10, 25], \n",
        " #'max_features': [0, 4, 6], \n",
        " 'max_depth': [10, 50, None], 'bootstrap': [True, False]}\n",
        "]\n",
        "\n",
        "grid_search_forest = GridSearchCV(rf, param_grid, cv=10)\n",
        "grid_search_forest.fit(X_train, y)\n",
        "grid_search_forest.best_estimator_"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_depth=10, n_estimators=25, random_state=44)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwgpRVhn4_vP",
        "outputId": "6e6a7177-51af-4335-bf1f-3cd8035eda13"
      },
      "source": [
        "rf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
        "                      max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
        "                      max_samples=None, min_impurity_decrease=0.0,\n",
        "                      min_impurity_split=None, min_samples_leaf=1,\n",
        "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                      n_estimators=25, n_jobs=None, oob_score=False,\n",
        "                      random_state=44, verbose=0, warm_start=False)\n",
        "rf.fit(X_train, y)\n",
        "y_preds_rf = rf.predict(X_test)\n",
        "y_preds_rf #  RSMLE 2.6"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5200932.26592148,  6037150.39786558,  7550227.73058032, ...,\n",
              "       44379508.45604303,  9888618.06894189,  9278429.54864628])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hfCjQcuYMM-"
      },
      "source": [
        "### XGBRegressor and Hyperparameter Tuning\n",
        "\n",
        "> Takes too long too run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym3N-LuMOdyo",
        "outputId": "e560b09f-6643-411e-d2d8-87f694c774af"
      },
      "source": [
        "# XGBoost Regressor With Hyperparameter Tuning\n",
        "\n",
        "param_tuning = {\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.5, 0.7],\n",
        "    'colsample_bytree': [0.5, 0.7],\n",
        "    'n_estimators' : [100, 200, 500],\n",
        "    'objective': ['reg:squarederror']\n",
        "}\n",
        "\n",
        "xgb_model = XGBRegressor(random_state=44)\n",
        "\n",
        "gsearch = GridSearchCV(estimator = xgb_model,\n",
        "                        param_grid = param_tuning,                        \n",
        "                        cv = 5,\n",
        "                        n_jobs = -1,\n",
        "                        verbose = 1)\n",
        "\n",
        "gsearch.fit(X_train,y)\n",
        "gsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3q2hb9SQ5rP",
        "outputId": "0ae0193b-a7b5-4ca6-e012-b89058c00981"
      },
      "source": [
        "# Fitting the data using the best Xgb params \n",
        "\n",
        "xgb = XGBRegressor(colsample_bytree = 0.5,\n",
        " learning_rate = 0.01,\n",
        " max_depth = 3,\n",
        " min_child_weight = 5,\n",
        " n_estimators = 500,\n",
        " objective = 'reg:squarederror',\n",
        " subsample = 0.5).fit(X_train, y)\n",
        "\n",
        "y_preds_xgb = xgb.predict(X_test)\n",
        "y_preds_xgb # RSMLE 3.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt2Mf221_MqS"
      },
      "source": [
        "### Deep Learning ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8tzAm_6_MMN",
        "outputId": "e7f482da-ff70-487c-beab-f0b00d4f7a02"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "ann_model = keras.models.Sequential()\n",
        "ann_model.add(keras.layers.Dense(5000 , activation=\"relu\", input_shape=X_train.shape[1:]))\n",
        "ann_model.add(keras.layers.Dense(1000, activation=\"relu\"))\n",
        "ann_model.add(keras.layers.Dense(2000, activation=\"relu\"))\n",
        "ann_model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "ann_model.add(keras.layers.Dense(500, activation=\"relu\"))\n",
        "ann_model.add(keras.layers.Dense(X_train.shape[1], activation=\"relu\"))\n",
        "ann_model.add(keras.layers.Dense(1))\n",
        "\n",
        "#model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "ann_model.compile(loss=\"mean_squared_logarithmic_error\", optimizer=keras.optimizers.SGD(lr=1e-1))\n",
        "history = ann_model.fit(X_train, y, epochs=100, batch_size=32, validation_split=0.2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "75/75 [==============================] - 2s 27ms/step - loss: 72.2143 - val_loss: 8.9596\n",
            "Epoch 2/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 9.8749 - val_loss: 8.2618\n",
            "Epoch 3/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 9.5377 - val_loss: 8.1798\n",
            "Epoch 4/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 9.6063 - val_loss: 8.1429\n",
            "Epoch 5/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 9.0347 - val_loss: 8.1310\n",
            "Epoch 6/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.7264 - val_loss: 8.1227\n",
            "Epoch 7/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 9.3253 - val_loss: 8.1173\n",
            "Epoch 8/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 10.6090 - val_loss: 8.0922\n",
            "Epoch 9/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 9.7201 - val_loss: 8.1018\n",
            "Epoch 10/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 8.9912 - val_loss: 8.0990\n",
            "Epoch 11/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 8.9366 - val_loss: 8.0882\n",
            "Epoch 12/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 9.5995 - val_loss: 8.0734\n",
            "Epoch 13/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 9.7415 - val_loss: 8.0696\n",
            "Epoch 14/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.6963 - val_loss: 8.0622\n",
            "Epoch 15/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.5940 - val_loss: 8.0496\n",
            "Epoch 16/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 11.3104 - val_loss: 8.0362\n",
            "Epoch 17/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 10.0118 - val_loss: 8.0343\n",
            "Epoch 18/100\n",
            "75/75 [==============================] - 2s 23ms/step - loss: 9.5911 - val_loss: 8.0341\n",
            "Epoch 19/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 10.0574 - val_loss: 8.0196\n",
            "Epoch 20/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 9.2830 - val_loss: 8.0095\n",
            "Epoch 21/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.6219 - val_loss: 8.0015\n",
            "Epoch 22/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 10.5125 - val_loss: 7.9830\n",
            "Epoch 23/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.4172 - val_loss: 7.9882\n",
            "Epoch 24/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.5378 - val_loss: 7.9777\n",
            "Epoch 25/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 9.3680 - val_loss: 7.9662\n",
            "Epoch 26/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.2159 - val_loss: 7.9577\n",
            "Epoch 27/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 8.9447 - val_loss: 7.9394\n",
            "Epoch 28/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 9.3246 - val_loss: 7.9247\n",
            "Epoch 29/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 8.8986 - val_loss: 7.9043\n",
            "Epoch 30/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 9.6771 - val_loss: 7.8796\n",
            "Epoch 31/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 9.6043 - val_loss: 7.8683\n",
            "Epoch 32/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.0637 - val_loss: 7.8448\n",
            "Epoch 33/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 8.8890 - val_loss: 7.8274\n",
            "Epoch 34/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.6901 - val_loss: 7.7786\n",
            "Epoch 35/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 8.9276 - val_loss: 7.7470\n",
            "Epoch 36/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 8.9801 - val_loss: 7.6975\n",
            "Epoch 37/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 8.7464 - val_loss: 7.6300\n",
            "Epoch 38/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.4711 - val_loss: 7.5130\n",
            "Epoch 39/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 7.8952 - val_loss: 7.3946\n",
            "Epoch 40/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 9.3452 - val_loss: 7.0542\n",
            "Epoch 41/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 8.5501 - val_loss: 6.8168\n",
            "Epoch 42/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 7.8027 - val_loss: 6.5173\n",
            "Epoch 43/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 8.8425 - val_loss: 6.3531\n",
            "Epoch 44/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 7.6691 - val_loss: 5.9993\n",
            "Epoch 45/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 7.6505 - val_loss: 5.7551\n",
            "Epoch 46/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 8.3130 - val_loss: 5.5909\n",
            "Epoch 47/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.7641 - val_loss: 5.4763\n",
            "Epoch 48/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 7.9996 - val_loss: 5.2339\n",
            "Epoch 49/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 6.7617 - val_loss: 4.9498\n",
            "Epoch 50/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 7.0839 - val_loss: 4.9978\n",
            "Epoch 51/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.6734 - val_loss: 5.3642\n",
            "Epoch 52/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.2865 - val_loss: 5.0862\n",
            "Epoch 53/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.6022 - val_loss: 4.8111\n",
            "Epoch 54/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.7100 - val_loss: 4.7090\n",
            "Epoch 55/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 5.9291 - val_loss: 4.6123\n",
            "Epoch 56/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.3686 - val_loss: 4.5850\n",
            "Epoch 57/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.9127 - val_loss: 4.8917\n",
            "Epoch 58/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 7.2267 - val_loss: 4.8221\n",
            "Epoch 59/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.2004 - val_loss: 5.8160\n",
            "Epoch 60/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.8505 - val_loss: 4.5478\n",
            "Epoch 61/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.1612 - val_loss: 4.6104\n",
            "Epoch 62/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.3865 - val_loss: 4.6581\n",
            "Epoch 63/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.6739 - val_loss: 4.3827\n",
            "Epoch 64/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.2924 - val_loss: 4.6955\n",
            "Epoch 65/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.0011 - val_loss: 4.5547\n",
            "Epoch 66/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.7665 - val_loss: 4.5126\n",
            "Epoch 67/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.6075 - val_loss: 4.4511\n",
            "Epoch 68/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.1229 - val_loss: 5.0715\n",
            "Epoch 69/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.0131 - val_loss: 4.3982\n",
            "Epoch 70/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.0921 - val_loss: 4.7412\n",
            "Epoch 71/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.8688 - val_loss: 4.5660\n",
            "Epoch 72/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.6027 - val_loss: 4.3004\n",
            "Epoch 73/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.2141 - val_loss: 5.8758\n",
            "Epoch 74/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 6.2163 - val_loss: 4.9174\n",
            "Epoch 75/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.3669 - val_loss: 4.3369\n",
            "Epoch 76/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.2372 - val_loss: 4.2754\n",
            "Epoch 77/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.8629 - val_loss: 4.3138\n",
            "Epoch 78/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 5.3198 - val_loss: 4.2748\n",
            "Epoch 79/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 6.2600 - val_loss: 4.1754\n",
            "Epoch 80/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 6.1812 - val_loss: 5.4263\n",
            "Epoch 81/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.3178 - val_loss: 4.6195\n",
            "Epoch 82/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.7130 - val_loss: 4.3285\n",
            "Epoch 83/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 6.1408 - val_loss: 4.2551\n",
            "Epoch 84/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.7743 - val_loss: 4.2328\n",
            "Epoch 85/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.5558 - val_loss: 5.3120\n",
            "Epoch 86/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.2128 - val_loss: 4.2615\n",
            "Epoch 87/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.1961 - val_loss: 4.1792\n",
            "Epoch 88/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.0865 - val_loss: 5.7571\n",
            "Epoch 89/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 6.2553 - val_loss: 4.3806\n",
            "Epoch 90/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 5.6047 - val_loss: 4.2702\n",
            "Epoch 91/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.7802 - val_loss: 4.2990\n",
            "Epoch 92/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 5.7224 - val_loss: 4.4099\n",
            "Epoch 93/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 6.0331 - val_loss: 4.2737\n",
            "Epoch 94/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.9716 - val_loss: 5.4017\n",
            "Epoch 95/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.5550 - val_loss: 4.8442\n",
            "Epoch 96/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 4.9933 - val_loss: 4.7972\n",
            "Epoch 97/100\n",
            "75/75 [==============================] - 2s 24ms/step - loss: 5.9396 - val_loss: 4.4816\n",
            "Epoch 98/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 6.7987 - val_loss: 4.4391\n",
            "Epoch 99/100\n",
            "75/75 [==============================] - 2s 28ms/step - loss: 5.8718 - val_loss: 4.3092\n",
            "Epoch 100/100\n",
            "75/75 [==============================] - 2s 25ms/step - loss: 6.3160 - val_loss: 4.2548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCIei9F8_w4m",
        "outputId": "170cdd00-86ff-456f-d45e-8a838f812b3b"
      },
      "source": [
        "final_model = ann_model\n",
        "final_predictions = final_model.predict(X_test)\n",
        "final_predictions # RSMLE = 2.44 ON KAGGLE"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  355788.9 ],\n",
              "       [  920661.8 ],\n",
              "       [  642327.44],\n",
              "       ...,\n",
              "       [37921730.  ],\n",
              "       [ 1868846.  ],\n",
              "       [ 1926150.2 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgxR5sXY18Kx"
      },
      "source": [
        "#### Creating a validation set for LGBMRegression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OvxcyGA18Ky"
      },
      "source": [
        "# Creating a validation set\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbJTk1DFYZhM"
      },
      "source": [
        "### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPQyjgg918Ky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4141e912-d872-4ea4-8c15-f601ae5f8b76"
      },
      "source": [
        "params = {'objective':'regression',\n",
        "         'num_leaves' : 30,\n",
        "         'min_data_in_leaf' : 20,\n",
        "         'max_depth' : 9,\n",
        "         'learning_rate': 0.004,\n",
        "         #'min_child_samples':100,\n",
        "         'feature_fraction':0.9,\n",
        "         \"bagging_freq\": 1,\n",
        "         \"bagging_fraction\": 0.9,\n",
        "         'lambda_l1': 0.2,\n",
        "         \"bagging_seed\": 11,\n",
        "         \"metric\": 'rmse',\n",
        "         #'subsample':.8, \n",
        "          #'colsample_bytree':.9,\n",
        "         \"random_state\" : 11,\n",
        "         \"verbosity\": -1}\n",
        "record = dict()\n",
        "model = lgb.train(params\n",
        "                      , lgb.Dataset(X_train, y_train)\n",
        "                      , num_boost_round = 100000\n",
        "                      , valid_sets = [lgb.Dataset(X_val, y_val)]\n",
        "                      , verbose_eval = 500\n",
        "                      , early_stopping_rounds = 500\n",
        "                      , callbacks = [lgb.record_evaluation(record)]\n",
        "                     )\n",
        "best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n",
        "\n",
        "test_pred = model.predict(X_test, num_iteration = model.best_iteration)# LGBMRegressor\n",
        "test_pred # RSMLE 2.8\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 500 rounds\n",
            "[500]\tvalid_0's rmse: 7.08181e+07\n",
            "[1000]\tvalid_0's rmse: 6.91692e+07\n",
            "Early stopping, best iteration is:\n",
            "[873]\tvalid_0's rmse: 6.914e+07\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7260247.84389243,  6175086.19452963,  7044947.30542968, ...,\n",
              "       41686547.25315428, 15375417.88791783, 13088185.63780073])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHlbahOX18Ky"
      },
      "source": [
        "## Creating Submission File\n",
        "\n",
        "* Made using `finalpredictions` from ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsg-GCSc18Ky"
      },
      "source": [
        "preds = pd.DataFrame(final_predictions, columns=['revenue'])\n",
        "submission = pd.concat([test['id'], preds], axis=1)\n",
        "submission.head()\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZQFiGjC18Ky"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}